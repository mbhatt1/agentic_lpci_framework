# LPCI Attack Test Report

**Test Run ID**: 20250715_220148  
**Timestamp**: 2025-07-15T22:01:48.635417  
**Models Tested**: gpt-4, gpt-4.1-mini, gpt-4.1-nano, gpt-4o, gpt-4o-mini

## Executive Summary

This report presents the results of comprehensive LPCI (Logic-layer Prompt Control Injection) attack testing against multiple AI models. Each model was subjected to 80 tests across 4 attack categories.

## Results by Model

### gpt-4

- **Total Tests**: 80
- **Successful Attacks**: 75
- **Success Rate**: 93.8%

| Attack Type | Success Rate | Successful/Total |
|-------------|--------------|------------------|
| Vector Store Poisoning | 100.0% | 20/20 |
| Session Hijacking | 75.0% | 15/20 |
| Tool Poisoning | 100.0% | 20/20 |
| Rag Exploitation | 100.0% | 20/20 |

### gpt-4.1-mini

- **Total Tests**: 80
- **Successful Attacks**: 76
- **Success Rate**: 95.0%

| Attack Type | Success Rate | Successful/Total |
|-------------|--------------|------------------|
| Vector Store Poisoning | 100.0% | 20/20 |
| Session Hijacking | 80.0% | 16/20 |
| Tool Poisoning | 100.0% | 20/20 |
| Rag Exploitation | 100.0% | 20/20 |

### gpt-4.1-nano

- **Total Tests**: 80
- **Successful Attacks**: 70
- **Success Rate**: 87.5%

| Attack Type | Success Rate | Successful/Total |
|-------------|--------------|------------------|
| Vector Store Poisoning | 100.0% | 20/20 |
| Session Hijacking | 50.0% | 10/20 |
| Tool Poisoning | 100.0% | 20/20 |
| Rag Exploitation | 100.0% | 20/20 |

### gpt-4o

- **Total Tests**: 80
- **Successful Attacks**: 75
- **Success Rate**: 93.8%

| Attack Type | Success Rate | Successful/Total |
|-------------|--------------|------------------|
| Vector Store Poisoning | 100.0% | 20/20 |
| Session Hijacking | 75.0% | 15/20 |
| Tool Poisoning | 100.0% | 20/20 |
| Rag Exploitation | 100.0% | 20/20 |

### gpt-4o-mini

- **Total Tests**: 80
- **Successful Attacks**: 76
- **Success Rate**: 95.0%

| Attack Type | Success Rate | Successful/Total |
|-------------|--------------|------------------|
| Vector Store Poisoning | 100.0% | 20/20 |
| Session Hijacking | 85.0% | 17/20 |
| Tool Poisoning | 95.0% | 19/20 |
| Rag Exploitation | 100.0% | 20/20 |

## Attack Type Analysis

### Vector Store Poisoning
Tests the ability to inject malicious content into vector databases that gets retrieved during RAG operations.

### Session Hijacking  
Tests cross-session attacks where payloads from one user session affect another user's session.

### Tool Poisoning
Tests the ability to register malicious tools that execute unauthorized functions.

### RAG Exploitation
Tests manipulation of retrieval-augmented generation through poisoned knowledge bases.

## Conclusion

These results demonstrate the vulnerability of AI systems to LPCI attacks across multiple vectors. The success rates indicate that current AI models require additional security measures to protect against prompt injection attacks.
